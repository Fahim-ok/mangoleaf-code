{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7255e0-3258-42fd-9bb6-c22d8cb8f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f92aae2-08b1-4e3b-9e45-292847cc1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e18eca-bde6-4838-b070-fb5fa1887dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0755c03-3a94-424b-a32d-a01cab6b8d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahim\\miniconda3\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D,BatchNormalization,Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4853c94-54e7-42aa-99ee-f99334af803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Main Directory\n",
    "input_path = r'I:/mango-prepo/'\n",
    "output_path = r'I:/mango-new-pre/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc0ea9c-a32b-4f04-a3fb-4f6003b827d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest_folder = os.listdir(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a2ea36-a3a4-43f6-8cfd-9364024d2b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import pywt\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    unsharp_mask = cv2.addWeighted(image, 2, blurred, -1, 0)\n",
    "    sharpened_image = np.uint8(np.clip(unsharp_mask, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def kalman_filter(image):\n",
    "    # Apply Kalman Filter to smooth the image\n",
    "    kalman = cv2.KalmanFilter(4, 2)\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = 1e-5 * np.eye(4, dtype=np.float32)\n",
    "    kalman.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32)\n",
    "\n",
    "    # Convert image to float32 for Kalman Filter\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Initialize Kalman Filter state\n",
    "    state = np.array([[image[0, 0]], [image[0, 1]], [0], [0]], dtype=np.float32)\n",
    "\n",
    "    for i in range(1, image.shape[0]):\n",
    "        # Predict\n",
    "        predicted_state = kalman.predict()\n",
    "\n",
    "        # Correct using measurement\n",
    "        measurement = np.array([[image[i, 0]], [image[i, 1]]], dtype=np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "\n",
    "        # Update image with corrected state\n",
    "        image[i, 0] = corrected_state[0, 0]\n",
    "        image[i, 1] = corrected_state[1, 0]\n",
    "\n",
    "    return image\n",
    "\n",
    "def wavelet_denoise(image, wavelet='db1', level=1):\n",
    "    # Apply 2D Discrete Wavelet Transform\n",
    "    coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
    "\n",
    "    # Thresholding coefficients (soft thresholding)\n",
    "    threshold = 0.1\n",
    "    coeffs = tuple(pywt.threshold(c, threshold, mode='soft') if isinstance(c, np.ndarray) else c for c in coeffs)\n",
    "\n",
    "    # Inverse 2D Discrete Wavelet Transform\n",
    "    denoised_image = pywt.waverec2(coeffs, wavelet, mode='per')\n",
    "\n",
    "    # Clip values to the valid range [0, 255]\n",
    "    denoised_image = np.uint8(np.clip(denoised_image, 0, 255))\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "def preprocess_image(image, gamma=1.0):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_image = laplacian(gray_image)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_image1 = highPassFiltering(transformed_image)\n",
    "\n",
    "    # Kalman Filtering\n",
    "    transformed_image2 = kalman_filter(transformed_image1)\n",
    "\n",
    "    # Gamma Transformation\n",
    "    gamma_transformed_image = np.power(transformed_image2 / 255.0, gamma) * 255.0\n",
    "    gamma_transformed_image = np.uint8(np.clip(gamma_transformed_image, 0, 255))\n",
    "\n",
    "    # Wavelet Denoising\n",
    "    denoised_image = wavelet_denoise(gamma_transformed_image)\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "# Loop over your dataset\n",
    "for segments in traintest_folder:\n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path, segments)\n",
    "\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "\n",
    "    # Individual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "\n",
    "        for i in images:\n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Preprocess the image with gamma transformation, wavelet denoising\n",
    "            preprocessed_image = preprocess_image(image, gamma=1.5)\n",
    "\n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), preprocessed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6674a-78fc-46ea-956c-5fe46e8d66be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de1b08f-7ac0-4cc2-b66c-038295033407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pyrso (from versions: none)\n",
      "ERROR: No matching distribution found for pyrso\n"
     ]
    }
   ],
   "source": [
    "pip install pyrso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800e5b05-57af-4dc8-8c3e-a113dab51c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyrso'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m join\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpywt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyrso\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RSO\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlaplacian\u001b[39m(image):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Apply Laplacian sharpening\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     laplacian \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mLaplacian(image, cv2\u001b[38;5;241m.\u001b[39mCV_64F)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyrso'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import pywt\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    unsharp_mask = cv2.addWeighted(image, 2, blurred, -1, 0)\n",
    "    sharpened_image = np.uint8(np.clip(unsharp_mask, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def kalman_filter(image):\n",
    "    # Apply Kalman Filter to smooth the image\n",
    "    kalman = cv2.KalmanFilter(4, 2)\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = 1e-5 * np.eye(4, dtype=np.float32)\n",
    "    kalman.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32)\n",
    "\n",
    "    # Convert image to float32 for Kalman Filter\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Initialize Kalman Filter state\n",
    "    state = np.array([[image[0, 0]], [image[0, 1]], [0], [0]], dtype=np.float32)\n",
    "\n",
    "    for i in range(1, image.shape[0]):\n",
    "        # Predict\n",
    "        predicted_state = kalman.predict()\n",
    "\n",
    "        # Correct using measurement\n",
    "        measurement = np.array([[image[i, 0]], [image[i, 1]]], dtype=np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "\n",
    "        # Update image with corrected state\n",
    "        image[i, 0] = corrected_state[0, 0]\n",
    "        image[i, 1] = corrected_state[1, 0]\n",
    "\n",
    "    return image\n",
    "\n",
    "def wavelet_denoise(image, wavelet='db1', level=1):\n",
    "    # Apply 2D Discrete Wavelet Transform\n",
    "    coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
    "\n",
    "    # Thresholding coefficients (soft thresholding)\n",
    "    threshold = 0.1\n",
    "    coeffs = tuple(pywt.threshold(c, threshold, mode='soft') if isinstance(c, np.ndarray) else c for c in coeffs)\n",
    "\n",
    "    # Inverse 2D Discrete Wavelet Transform\n",
    "    denoised_image = pywt.waverec2(coeffs, wavelet, mode='per')\n",
    "\n",
    "    # Clip values to the valid range [0, 255]\n",
    "    denoised_image = np.uint8(np.clip(denoised_image, 0, 255))\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "def preprocess_image(image, gamma=1.0):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_image = laplacian(gray_image)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_image1 = highPassFiltering(transformed_image)\n",
    "\n",
    "    # Kalman Filtering\n",
    "    transformed_image2 = kalman_filter(transformed_image1)\n",
    "\n",
    "    # Gamma Transformation\n",
    "    gamma_transformed_image = np.power(transformed_image2 / 255.0, gamma) * 255.0\n",
    "    gamma_transformed_image = np.uint8(np.clip(gamma_transformed_image, 0, 255))\n",
    "\n",
    "    # Wavelet Denoising\n",
    "    denoised_image = wavelet_denoise(gamma_transformed_image)\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "# Loop over your dataset\n",
    "for segments in traintest_folder:\n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path, segments)\n",
    "\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "\n",
    "    # Individual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "\n",
    "        for i in images:\n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Preprocess the image with gamma transformation, wavelet denoising\n",
    "            preprocessed_image = preprocess_image(image, gamma=1.5)\n",
    "\n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), preprocessed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d96a2-8731-495b-8241-99ca4fdbd6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c75e80-3e28-4578-9142-79c204f8313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test ----------------------------------------------\n",
      "Working on African Jambo ------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(join(input_class_folder, i), cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Preprocess the image with AOWMF filtering, gamma transformation, wavelet denoising\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m preprocessed_image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m filename \u001b[38;5;241m=\u001b[39m join(output_class_folder, i)\n\u001b[0;32m    154\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filename), preprocessed_image)\n",
      "Cell \u001b[1;32mIn[8], line 102\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image, gamma)\u001b[0m\n\u001b[0;32m     99\u001b[0m gray_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# AOWMF Filtering\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m aowmf_filtered_image \u001b[38;5;241m=\u001b[39m \u001b[43maowmf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Laplacian Transformation\u001b[39;00m\n\u001b[0;32m    105\u001b[0m transformed_image \u001b[38;5;241m=\u001b[39m laplacian(aowmf_filtered_image)\n",
      "Cell \u001b[1;32mIn[8], line 86\u001b[0m, in \u001b[0;36maowmf\u001b[1;34m(image, filter_size)\u001b[0m\n\u001b[0;32m     83\u001b[0m local_window \u001b[38;5;241m=\u001b[39m image[start_row:end_row, start_col:end_col]\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Calculate local mean and standard deviation\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m local_mean \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m local_std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(local_window)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Calculate the weight for each pixel\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:125\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret)\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result:\n\u001b[0;32m    127\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret \u001b[38;5;241m/\u001b[39m rcount)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import pywt\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    unsharp_mask = cv2.addWeighted(image, 2, blurred, -1, 0)\n",
    "    sharpened_image = np.uint8(np.clip(unsharp_mask, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def kalman_filter(image):\n",
    "    # Apply Kalman Filter to smooth the image\n",
    "    kalman = cv2.KalmanFilter(4, 2)\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = 1e-5 * np.eye(4, dtype=np.float32)\n",
    "    kalman.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32)\n",
    "\n",
    "    # Convert image to float32 for Kalman Filter\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Initialize Kalman Filter state\n",
    "    state = np.array([[image[0, 0]], [image[0, 1]], [0], [0]], dtype=np.float32)\n",
    "\n",
    "    for i in range(1, image.shape[0]):\n",
    "        # Predict\n",
    "        predicted_state = kalman.predict()\n",
    "\n",
    "        # Correct using measurement\n",
    "        measurement = np.array([[image[i, 0]], [image[i, 1]]], dtype=np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "\n",
    "        # Update image with corrected state\n",
    "        image[i, 0] = corrected_state[0, 0]\n",
    "        image[i, 1] = corrected_state[1, 0]\n",
    "\n",
    "    return image\n",
    "\n",
    "def wavelet_denoise(image, wavelet='db1', level=1):\n",
    "    # Apply 2D Discrete Wavelet Transform\n",
    "    coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
    "\n",
    "    # Thresholding coefficients (soft thresholding)\n",
    "    threshold = 0.1\n",
    "    coeffs = tuple(pywt.threshold(c, threshold, mode='soft') if isinstance(c, np.ndarray) else c for c in coeffs)\n",
    "\n",
    "    # Inverse 2D Discrete Wavelet Transform\n",
    "    denoised_image = pywt.waverec2(coeffs, wavelet, mode='per')\n",
    "\n",
    "    # Clip values to the valid range [0, 255]\n",
    "    denoised_image = np.uint8(np.clip(denoised_image, 0, 255))\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "def aowmf(image, filter_size=3):\n",
    "    rows, cols = image.shape\n",
    "    filtered_image = np.zeros_like(image, dtype=np.float64)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # Define the local window\n",
    "            start_row = max(0, i - filter_size // 2)\n",
    "            end_row = min(rows, i + filter_size // 2 + 1)\n",
    "            start_col = max(0, j - filter_size // 2)\n",
    "            end_col = min(cols, j + filter_size // 2 + 1)\n",
    "\n",
    "            # Extract the local window\n",
    "            local_window = image[start_row:end_row, start_col:end_col]\n",
    "\n",
    "            # Calculate local mean and standard deviation\n",
    "            local_mean = np.mean(local_window)\n",
    "            local_std = np.std(local_window)\n",
    "\n",
    "            # Calculate the weight for each pixel\n",
    "            weight = 1.0 / (1.0 + (image[i, j] - local_mean) / (0.1 * (local_std + 1)))\n",
    "\n",
    "            # Update the filtered pixel value\n",
    "            filtered_image[i, j] = np.sum(local_window * weight) / np.sum(weight)\n",
    "\n",
    "    return np.uint8(np.clip(filtered_image, 0, 255))\n",
    "\n",
    "def preprocess_image(image, gamma=1.0):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # AOWMF Filtering\n",
    "    aowmf_filtered_image = aowmf(gray_image, filter_size=3)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_image = laplacian(aowmf_filtered_image)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_image1 = highPassFiltering(transformed_image)\n",
    "\n",
    "    # Kalman Filtering\n",
    "    transformed_image2 = kalman_filter(transformed_image1)\n",
    "\n",
    "    # Gamma Transformation\n",
    "    gamma_transformed_image = np.power(transformed_image2 / 255.0, gamma) * 255.0\n",
    "    gamma_transformed_image = np.uint8(np.clip(gamma_transformed_image, 0, 255))\n",
    "\n",
    "    # Wavelet Denoising\n",
    "    denoised_image = wavelet_denoise(gamma_transformed_image)\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "# Loop over your dataset\n",
    "for segments in traintest_folder:\n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path, segments)\n",
    "\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "\n",
    "    # Individual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "\n",
    "        for i in images:\n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Preprocess the image with AOWMF filtering, gamma transformation, wavelet denoising\n",
    "            preprocessed_image = preprocess_image(image, gamma=1.5)\n",
    "\n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), preprocessed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e91cc-811e-4c54-9a25-4e84ee3f6809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test ----------------------------------------------\n",
      "Working on African Jambo ------------------\n",
      "Working on Aprupali ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahim\\AppData\\Local\\Temp\\ipykernel_17592\\1767694625.py:87: RuntimeWarning: invalid value encountered in power\n",
      "  gamma_transformed_image = np.power(transformed_image2 / 255.0, gamma) * 255.0\n",
      "C:\\Users\\Fahim\\AppData\\Local\\Temp\\ipykernel_17592\\1767694625.py:88: RuntimeWarning: invalid value encountered in cast\n",
      "  gamma_transformed_image = np.uint8(np.clip(gamma_transformed_image, 0, 255))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Baper Bari ------------------\n",
      "Working on Bari 11 ------------------\n",
      "Working on Bari 13 ------------------\n",
      "Working on Bari 4 ------------------\n",
      "Working on Bari 7 ------------------\n",
      "Working on Bari 8 ------------------\n",
      "Working on Bari 9 ------------------\n",
      "Working on Fazlee ------------------\n",
      "Working on Gopal Vog ------------------\n",
      "Working on Haribhanga ------------------\n",
      "Working on Him Sagor ------------------\n",
      "Working on Indian Totapori ------------------\n",
      "Working on Kacha Mitha ------------------\n",
      "Working on King Breunei ------------------\n",
      "Working on Lengra ------------------\n",
      "Working on Maryam ------------------\n",
      "Working on Modhurani ------------------\n",
      "Working on Phillipine Honey Dew ------------------\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import pywt\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    unsharp_mask = cv2.addWeighted(image, 2, blurred, -1, 0)\n",
    "    sharpened_image = np.uint8(np.clip(unsharp_mask, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def kalman_filter(image):\n",
    "    # Apply Kalman Filter to smooth the image\n",
    "    kalman = cv2.KalmanFilter(4, 2)\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = 1e-5 * np.eye(4, dtype=np.float32)\n",
    "    kalman.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32)\n",
    "\n",
    "    # Convert image to float32 for Kalman Filter\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Initialize Kalman Filter state\n",
    "    state = np.array([[image[0, 0]], [image[0, 1]], [0], [0]], dtype=np.float32)\n",
    "\n",
    "    for i in range(1, image.shape[0]):\n",
    "        # Predict\n",
    "        predicted_state = kalman.predict()\n",
    "\n",
    "        # Correct using measurement\n",
    "        measurement = np.array([[image[i, 0]], [image[i, 1]]], dtype=np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "\n",
    "        # Update image with corrected state\n",
    "        image[i, 0] = corrected_state[0, 0]\n",
    "        image[i, 1] = corrected_state[1, 0]\n",
    "\n",
    "    return image\n",
    "\n",
    "def wavelet_denoise(image, wavelet='db1', level=1):\n",
    "    # Apply 2D Discrete Wavelet Transform\n",
    "    coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
    "\n",
    "    # Thresholding coefficients (soft thresholding)\n",
    "    threshold = 0.1\n",
    "    coeffs = tuple(pywt.threshold(c, threshold, mode='soft') if isinstance(c, np.ndarray) else c for c in coeffs)\n",
    "\n",
    "    # Inverse 2D Discrete Wavelet Transform\n",
    "    denoised_image = pywt.waverec2(coeffs, wavelet, mode='per')\n",
    "\n",
    "    # Clip values to the valid range [0, 255]\n",
    "    denoised_image = np.uint8(np.clip(denoised_image, 0, 255))\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "def preprocess_image(image, gamma=1.0):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Optimized Bilateral Filtering\n",
    "    bilateral_filtered_image = cv2.bilateralFilter(gray_image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_image = laplacian(bilateral_filtered_image)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_image1 = highPassFiltering(transformed_image)\n",
    "\n",
    "    # Kalman Filtering\n",
    "    transformed_image2 = kalman_filter(transformed_image1)\n",
    "\n",
    "    # Gamma Transformation\n",
    "    gamma_transformed_image = np.power(transformed_image2 / 255.0, gamma) * 255.0\n",
    "    gamma_transformed_image = np.uint8(np.clip(gamma_transformed_image, 0, 255))\n",
    "\n",
    "    # Wavelet Denoising\n",
    "    denoised_image = wavelet_denoise(gamma_transformed_image)\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "# Loop over your dataset\n",
    "for segments in traintest_folder:\n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path, segments)\n",
    "\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "\n",
    "    # Individual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "\n",
    "        for i in images:\n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Preprocess the image with gamma transformation, wavelet denoising, and optimized bilateral filtering\n",
    "            preprocessed_image = preprocess_image(image, gamma=1.5)\n",
    "\n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), preprocessed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5673d-acaa-4e1d-8dc4-a3ed074a8e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

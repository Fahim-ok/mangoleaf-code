{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a225acf-82b0-4bb6-860d-70e1ca18ad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\fahim\\miniconda3\\lib\\site-packages (0.21.0)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.22.0-cp311-cp311-win_amd64.whl (719 kB)\n",
      "                                              0.0/719.8 kB ? eta -:--:--\n",
      "                                              10.2/719.8 kB ? eta -:--:--\n",
      "     -                                     30.7/719.8 kB 435.7 kB/s eta 0:00:02\n",
      "     --                                    41.0/719.8 kB 326.8 kB/s eta 0:00:03\n",
      "     ----                                  81.9/719.8 kB 508.4 kB/s eta 0:00:02\n",
      "     ------                               122.9/719.8 kB 599.1 kB/s eta 0:00:01\n",
      "     ----------                           204.8/719.8 kB 827.9 kB/s eta 0:00:01\n",
      "     -------------                        276.5/719.8 kB 896.4 kB/s eta 0:00:01\n",
      "     -----------------------                440.3/719.8 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------              491.5/719.8 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------              491.5/719.8 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  716.8/719.8 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 719.8/719.8 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from tensorflow-addons) (23.0)\n",
      "Installing collected packages: tensorflow-addons\n",
      "  Attempting uninstall: tensorflow-addons\n",
      "    Found existing installation: tensorflow-addons 0.21.0\n",
      "    Uninstalling tensorflow-addons-0.21.0:\n",
      "      Successfully uninstalled tensorflow-addons-0.21.0\n",
      "Successfully installed tensorflow-addons-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aceb410-e2d1-408d-84db-fafdc67e2442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\fahim\\miniconda3\\lib\\site-packages (1.26.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.2-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "                                              0.0/15.8 MB ? eta -:--:--\n",
      "                                              0.0/15.8 MB ? eta -:--:--\n",
      "                                             0.0/15.8 MB 330.3 kB/s eta 0:00:48\n",
      "                                             0.0/15.8 MB 245.8 kB/s eta 0:01:05\n",
      "                                             0.1/15.8 MB 393.8 kB/s eta 0:00:40\n",
      "                                             0.1/15.8 MB 554.9 kB/s eta 0:00:29\n",
      "                                             0.2/15.8 MB 734.2 kB/s eta 0:00:22\n",
      "                                             0.3/15.8 MB 787.7 kB/s eta 0:00:20\n",
      "     -                                        0.4/15.8 MB 1.1 MB/s eta 0:00:14\n",
      "     -                                        0.5/15.8 MB 1.2 MB/s eta 0:00:13\n",
      "     -                                        0.7/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "     --                                       1.0/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "     --                                       1.1/15.8 MB 2.1 MB/s eta 0:00:08\n",
      "     ----                                     1.6/15.8 MB 2.7 MB/s eta 0:00:06\n",
      "     -----                                    2.1/15.8 MB 3.3 MB/s eta 0:00:05\n",
      "     ------                                   2.5/15.8 MB 3.7 MB/s eta 0:00:04\n",
      "     -------                                  3.1/15.8 MB 4.2 MB/s eta 0:00:04\n",
      "     ---------                                3.6/15.8 MB 4.6 MB/s eta 0:00:03\n",
      "     ---------                                3.6/15.8 MB 4.7 MB/s eta 0:00:03\n",
      "     ---------                                3.6/15.8 MB 4.7 MB/s eta 0:00:03\n",
      "     ---------                                3.7/15.8 MB 4.0 MB/s eta 0:00:04\n",
      "     ----------                               4.0/15.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ----------                               4.0/15.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ----------                               4.2/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ----------                               4.2/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ----------                               4.2/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ----------                               4.2/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ----------                               4.2/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ----------                               4.2/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------                       7.4/15.8 MB 5.5 MB/s eta 0:00:02\n",
      "     -------------------                      7.8/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "     -------------------                      7.9/15.8 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------                    8.3/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "     ---------------------                    8.3/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "     ---------------------                    8.3/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "     ---------------------                    8.4/15.8 MB 5.2 MB/s eta 0:00:02\n",
      "     ----------------------                   8.8/15.8 MB 5.2 MB/s eta 0:00:02\n",
      "     -----------------------                  9.1/15.8 MB 5.4 MB/s eta 0:00:02\n",
      "     -----------------------                  9.1/15.8 MB 5.4 MB/s eta 0:00:02\n",
      "     -----------------------                  9.1/15.8 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------------                 9.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------------------                 9.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "     ---------------------------              10.8/15.8 MB 6.8 MB/s eta 0:00:01\n",
      "     -----------------------------            11.5/15.8 MB 7.2 MB/s eta 0:00:01\n",
      "     -----------------------------            11.7/15.8 MB 7.0 MB/s eta 0:00:01\n",
      "     -----------------------------            11.8/15.8 MB 7.0 MB/s eta 0:00:01\n",
      "     -----------------------------            11.8/15.8 MB 7.0 MB/s eta 0:00:01\n",
      "     -----------------------------            11.8/15.8 MB 7.0 MB/s eta 0:00:01\n",
      "     -----------------------------            11.8/15.8 MB 6.4 MB/s eta 0:00:01\n",
      "     -----------------------------            11.8/15.8 MB 6.4 MB/s eta 0:00:01\n",
      "     --------------------------------         12.7/15.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ----------------------------------       13.6/15.8 MB 6.4 MB/s eta 0:00:01\n",
      "     -----------------------------------      13.9/15.8 MB 6.9 MB/s eta 0:00:01\n",
      "     -----------------------------------      14.2/15.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ------------------------------------     14.3/15.8 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     14.5/15.8 MB 8.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    14.7/15.8 MB 8.0 MB/s eta 0:00:01\n",
      "     -------------------------------------    14.9/15.8 MB 7.7 MB/s eta 0:00:01\n",
      "     --------------------------------------   15.1/15.8 MB 7.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   15.3/15.8 MB 7.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.5/15.8 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.7/15.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.8/15.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.8/15.8 MB 6.5 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "Successfully installed numpy-1.26.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e14f3c4-dfff-4d08-8aaa-6fffc9f3b8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
      "                                              0.0/294.6 kB ? eta -:--:--\n",
      "     -                                        10.2/294.6 kB ? eta -:--:--\n",
      "     ---                                   30.7/294.6 kB 259.2 kB/s eta 0:00:02\n",
      "     -----                                 41.0/294.6 kB 245.8 kB/s eta 0:00:02\n",
      "     ---------                             71.7/294.6 kB 357.2 kB/s eta 0:00:01\n",
      "     ---------------                      122.9/294.6 kB 514.3 kB/s eta 0:00:01\n",
      "     -----------------------              194.6/294.6 kB 692.9 kB/s eta 0:00:01\n",
      "     ----------------------------         235.5/294.6 kB 758.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ 294.6/294.6 kB 864.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ff01b8-d3be-4849-aaa5-84ae2d0288e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahim\\miniconda3\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D,BatchNormalization,Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7222b578-e71c-4244-b04f-8345a0971605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Main Directory\n",
    "input_path = r'G:/Desktop/knee/knee/PreprocessedData/'\n",
    "output_path = r'G:/Desktop/knee/knee/new-process/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e7e388-7ba8-4d43-b5d6-9ee928de1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest_folder = os.listdir(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe55465b-d23b-4dd6-8a5f-2740928712aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    equ = cv2.equalizeHist(image)\n",
    "    return equ\n",
    "\n",
    "def gamma_correction(image, gamma=1.0):\n",
    "    gamma_corrected = np.power(image / 255.0, gamma) * 255.0\n",
    "    return gamma_corrected.astype('uint8')\n",
    "\n",
    "def convert_to_hsv(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    return hsv_image\n",
    "\n",
    "def morphological_transform(image):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    morph_transformed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    return morph_transformed\n",
    "\n",
    "def adaptive_threshold(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    return adaptive_thresh\n",
    "\n",
    "def augment_image(image):\n",
    "    rows, cols, _ = image.shape\n",
    "    angle = np.random.randint(-30, 30)\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "    augmented_image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    return augmented_image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Manually define the Region of Interest (ROI)\n",
    "    x, y, w, h = 100, 50, 200, 150  # Example coordinates (adjust as needed)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "\n",
    "    # Convert the ROI to grayscale\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Canny Edge Detection to the ROI\n",
    "    edges_roi = cv2.Canny(gray_roi, 100, 200)\n",
    "\n",
    "    # Apply Gaussian Blur for noise reduction\n",
    "    blurred_roi = cv2.GaussianBlur(edges_roi, (5, 5), 0)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_roi = laplacian(roi)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_roi1 = highPassFiltering(transformed_roi)\n",
    "\n",
    "    # Additional Preprocessing\n",
    "    transformed_roi2 = histogram_equalization(transformed_roi1)\n",
    "    transformed_roi3 = gamma_correction(transformed_roi2, gamma=1.2)\n",
    "    transformed_roi4 = convert_to_hsv(transformed_roi3)\n",
    "    transformed_roi5 = morphological_transform(transformed_roi4)\n",
    "    transformed_roi6 = adaptive_threshold(transformed_roi5)\n",
    "\n",
    "    # Augmentation\n",
    "    augmented_roi = augment_image(transformed_roi6)\n",
    "\n",
    "    # Extract HOG features for the ROI\n",
    "    hog_features_roi = extract_hog_features(roi)\n",
    "\n",
    "    # Extract LBP features for the ROI\n",
    "    lbp_features_roi = extract_lbp_features(roi)\n",
    "\n",
    "    # Extract color histogram features for the ROI\n",
    "    color_hist_features_roi = extract_color_histogram(roi)\n",
    "\n",
    "    # Append HOG, LBP, and color histogram features to the flattened ROI\n",
    "    flattened_roi = augmented_roi.flatten()\n",
    "    features_with_hog_lbp_color_roi = np.concatenate((flattened_roi, hog_features_roi.flatten(), lbp_features_roi.flatten(), color_hist_features_roi))\n",
    "\n",
    "    return features_with_hog_lbp_color_roi\n",
    "\n",
    "\n",
    "# The rest of your code remains unchanged...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9889fe-57f2-4c87-b478-6bb38675941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test ----------------------------------------------\n",
      "Working on 0 ------------------\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x0114d669::Set<3,-1,-1>,struct cv::impl::A0x0114d669::Set<0,5,-1>,3>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 132\u001b[0m\n\u001b[0;32m    129\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(join(input_class_folder, i), cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Preprocess the image\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m preprocessed_image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m filename \u001b[38;5;241m=\u001b[39m join(output_class_folder, i)\n\u001b[0;32m    135\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filename), preprocessed_image)\n",
      "Cell \u001b[1;32mIn[16], line 79\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     77\u001b[0m transformed_roi2 \u001b[38;5;241m=\u001b[39m histogram_equalization(transformed_roi1)\n\u001b[0;32m     78\u001b[0m transformed_roi3 \u001b[38;5;241m=\u001b[39m gamma_correction(transformed_roi2, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.2\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m transformed_roi4 \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_hsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_roi3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m transformed_roi5 \u001b[38;5;241m=\u001b[39m morphological_transform(transformed_roi4)\n\u001b[0;32m     81\u001b[0m transformed_roi6 \u001b[38;5;241m=\u001b[39m adaptive_threshold(transformed_roi5)\n",
      "Cell \u001b[1;32mIn[16], line 36\u001b[0m, in \u001b[0;36mconvert_to_hsv\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_hsv\u001b[39m(image):\n\u001b[1;32m---> 36\u001b[0m     hsv_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2HSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hsv_image\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x0114d669::Set<3,-1,-1>,struct cv::impl::A0x0114d669::Set<0,5,-1>,3>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    # Convert the image to grayscale if it's not already\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_image = image\n",
    "\n",
    "    # Apply histogram equalization\n",
    "    equ = cv2.equalizeHist(gray_image)\n",
    "    return equ\n",
    "\n",
    "def gamma_correction(image, gamma=1.0):\n",
    "    gamma_corrected = np.power(image / 255.0, gamma) * 255.0\n",
    "    return gamma_corrected.astype('uint8')\n",
    "\n",
    "def convert_to_hsv(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    return hsv_image\n",
    "\n",
    "def morphological_transform(image):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    morph_transformed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    return morph_transformed\n",
    "\n",
    "def adaptive_threshold(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    return adaptive_thresh\n",
    "\n",
    "def augment_image(image):\n",
    "    rows, cols, _ = image.shape\n",
    "    angle = np.random.randint(-30, 30)\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "    augmented_image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    return augmented_image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Manually define the Region of Interest (ROI)\n",
    "    x, y, w, h = 100, 50, 200, 150  # Example coordinates (adjust as needed)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "\n",
    "    # Convert the ROI to grayscale\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Canny Edge Detection to the ROI\n",
    "    edges_roi = cv2.Canny(gray_roi, 100, 200)\n",
    "\n",
    "    # Apply Gaussian Blur for noise reduction\n",
    "    blurred_roi = cv2.GaussianBlur(edges_roi, (5, 5), 0)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_roi = laplacian(roi)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_roi1 = highPassFiltering(transformed_roi)\n",
    "\n",
    "    # Additional Preprocessing\n",
    "    transformed_roi2 = histogram_equalization(transformed_roi1)\n",
    "    transformed_roi3 = gamma_correction(transformed_roi2, gamma=1.2)\n",
    "    transformed_roi4 = convert_to_hsv(transformed_roi3)\n",
    "    transformed_roi5 = morphological_transform(transformed_roi4)\n",
    "    transformed_roi6 = adaptive_threshold(transformed_roi5)\n",
    "\n",
    "    # Augmentation\n",
    "    augmented_roi = augment_image(transformed_roi6)\n",
    "\n",
    "    # Extract HOG features for the ROI\n",
    "    # You need to implement or import the extract_hog_features function\n",
    "\n",
    "    # Extract LBP features for the ROI\n",
    "    # You need to implement or import the extract_lbp_features function\n",
    "\n",
    "    # Extract color histogram features for the ROI\n",
    "    color_hist_features_roi = extract_color_histogram(roi)\n",
    "\n",
    "    # Append HOG, LBP, and color histogram features to the flattened ROI\n",
    "    flattened_roi = augmented_roi.flatten()\n",
    "    features_with_hog_lbp_color_roi = np.concatenate((flattened_roi, color_hist_features_roi.flatten()))\n",
    "\n",
    "    return features_with_hog_lbp_color_roi\n",
    "\n",
    "# The rest of your code remains unchanged...\n",
    "\n",
    "# Loop over your dataset\n",
    "for segments in traintest_folder:\n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path, segments)\n",
    "\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "\n",
    "    # Individual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "\n",
    "        for i in images:\n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Preprocess the image\n",
    "            preprocessed_image = preprocess_image(image)\n",
    "\n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), preprocessed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb91fb1a-542c-4b31-aa71-3866420d512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test ----------------------------------------------\n",
      "Working on 0 ------------------\n",
      "Working on 1 ------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m transformed_image1 \u001b[38;5;241m=\u001b[39m highPassFiltering(transformed_image)\n\u001b[0;32m     85\u001b[0m  \u001b[38;5;66;03m# kalman Filtering\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m transformed_image2 \u001b[38;5;241m=\u001b[39m  \u001b[43mkalman_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_image1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m filename \u001b[38;5;241m=\u001b[39m join(output_class_folder, i)\n\u001b[0;32m     91\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filename), transformed_image)\n",
      "Cell \u001b[1;32mIn[18], line 42\u001b[0m, in \u001b[0;36mkalman_filter\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Correct using measurement\u001b[39;00m\n\u001b[0;32m     41\u001b[0m measurement \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[image[i, \u001b[38;5;241m0\u001b[39m]], [image[i, \u001b[38;5;241m1\u001b[39m]]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 42\u001b[0m corrected_state \u001b[38;5;241m=\u001b[39m \u001b[43mkalman\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeasurement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Update image with corrected state\u001b[39;00m\n\u001b[0;32m     45\u001b[0m image[i, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m corrected_state[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(gray - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    blurred = cv2.GaussianBlur(gray, (0, 0), 3)\n",
    "    unsharp_mask = cv2.addWeighted(gray, 2, blurred, -1, 0)\n",
    "    sharpened_image = np.uint8(np.clip(unsharp_mask, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(gray, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "def kalman_filter(image):\n",
    "    # Apply Kalman Filter to smooth the image\n",
    "    kalman = cv2.KalmanFilter(4, 2)\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = 1e-5 * np.eye(4, dtype=np.float32)\n",
    "    kalman.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32)\n",
    "\n",
    "    # Convert image to float32 for Kalman Filter\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Initialize Kalman Filter state\n",
    "    state = np.array([[image[0, 0]], [image[0, 1]], [0], [0]], dtype=np.float32)\n",
    "\n",
    "    for i in range(1, image.shape[0]):\n",
    "        # Predict\n",
    "        predicted_state = kalman.predict()\n",
    "\n",
    "        # Correct using measurement\n",
    "        measurement = np.array([[image[i, 0]], [image[i, 1]]], dtype=np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "\n",
    "        # Update image with corrected state\n",
    "        image[i, 0] = corrected_state[0, 0]\n",
    "        image[i, 1] = corrected_state[1, 0]\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "for segments in traintest_folder:\n",
    "    \n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path,segments)\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "        \n",
    "    # Indiidual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        \n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "        \n",
    "        for i in images:\n",
    "            \n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "            # Laplacian Transformation\n",
    "            transformed_image = laplacian(image)\n",
    "            # High Pass Filtering\n",
    "            transformed_image1 = highPassFiltering(transformed_image)\n",
    "             # kalman Filtering\n",
    "            transformed_image2 =  kalman_filter(transformed_image1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc7cb673-019d-4bfe-9452-c1354a6a0c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test ----------------------------------------------\n",
      "Working on 0 ------------------\n",
      "Working on 1 ------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 98\u001b[0m\n\u001b[0;32m     94\u001b[0m images \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(input_class_folder)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# Read Image\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_class_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Preprocess the image within the ROI\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     preprocessed_roi \u001b[38;5;241m=\u001b[39m preprocess_roi(image)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    unsharp_mask = cv2.addWeighted(image, 2, blurred, -1, 0)\n",
    "    sharpened_image = np.uint8(np.clip(unsharp_mask, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def kalman_filter(image):\n",
    "    # Apply Kalman Filter to smooth the image\n",
    "    kalman = cv2.KalmanFilter(4, 2)\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = 1e-5 * np.eye(4, dtype=np.float32)\n",
    "    kalman.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32)\n",
    "\n",
    "    # Convert image to float32 for Kalman Filter\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Initialize Kalman Filter state\n",
    "    state = np.array([[image[0, 0]], [image[0, 1]], [0], [0]], dtype=np.float32)\n",
    "\n",
    "    for i in range(1, image.shape[0]):\n",
    "        # Predict\n",
    "        predicted_state = kalman.predict()\n",
    "\n",
    "        # Correct using measurement\n",
    "        measurement = np.array([[image[i, 0]], [image[i, 1]]], dtype=np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "\n",
    "        # Update image with corrected state\n",
    "        image[i, 0] = corrected_state[0, 0]\n",
    "        image[i, 1] = corrected_state[1, 0]\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_roi(image):\n",
    "    # Manually define the Region of Interest (ROI)\n",
    "    x, y, w, h = 100, 50, 200, 150  # Example coordinates (adjust as needed)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "\n",
    "    # Convert the ROI to grayscale\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_roi = laplacian(gray_roi)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_roi1 = highPassFiltering(transformed_roi)\n",
    "\n",
    "    # Kalman Filtering\n",
    "    transformed_roi2 = kalman_filter(transformed_roi1)\n",
    "\n",
    "    return transformed_roi2\n",
    "\n",
    "# Loop over your dataset\n",
    "for segments in traintest_folder:\n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path, segments)\n",
    "\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "\n",
    "    # Individual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "\n",
    "        for i in images:\n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Preprocess the image within the ROI\n",
    "            preprocessed_roi = preprocess_roi(image)\n",
    "\n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), preprocessed_roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfec365d-2be7-4197-9c73-c9e3b659d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test ----------------------------------------------\n",
      "Working on 0 ------------------\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1555: error: (-2:Unspecified error) in function 'double __cdecl cv::threshold(const class cv::_InputArray &,const class cv::_OutputArray &,double,double,int)'\n> THRESH_OTSU mode:\n>     'src_type == CV_8UC1 || src_type == CV_16UC1'\n> where\n>     'src_type' is 5 (CV_32FC1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(join(input_class_folder, i), cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Preprocess the image within the ROI\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m preprocessed_roi \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_roi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m filename \u001b[38;5;241m=\u001b[39m join(output_class_folder, i)\n\u001b[0;32m    107\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filename), preprocessed_roi)\n",
      "Cell \u001b[1;32mIn[28], line 71\u001b[0m, in \u001b[0;36mpreprocess_roi\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     68\u001b[0m transformed_roi2 \u001b[38;5;241m=\u001b[39m kalman_filter(transformed_roi1)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Apply Otsu's thresholding\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m _, thresholded_roi \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_roi2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTHRESH_BINARY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTHRESH_OTSU\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m thresholded_roi\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1555: error: (-2:Unspecified error) in function 'double __cdecl cv::threshold(const class cv::_InputArray &,const class cv::_OutputArray &,double,double,int)'\n> THRESH_OTSU mode:\n>     'src_type == CV_8UC1 || src_type == CV_16UC1'\n> where\n>     'src_type' is 5 (CV_32FC1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    unsharp_mask = cv2.addWeighted(image, 2, blurred, -1, 0)\n",
    "    sharpened_image = np.uint8(np.clip(unsharp_mask, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def kalman_filter(image):\n",
    "    # Apply Kalman Filter to smooth the image\n",
    "    kalman = cv2.KalmanFilter(4, 2)\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = 1e-5 * np.eye(4, dtype=np.float32)\n",
    "    kalman.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32)\n",
    "\n",
    "    # Convert image to float32 for Kalman Filter\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Initialize Kalman Filter state\n",
    "    state = np.array([[image[0, 0]], [image[0, 1]], [0], [0]], dtype=np.float32)\n",
    "\n",
    "    for i in range(1, image.shape[0]):\n",
    "        # Predict\n",
    "        predicted_state = kalman.predict()\n",
    "\n",
    "        # Correct using measurement\n",
    "        measurement = np.array([[image[i, 0]], [image[i, 1]]], dtype=np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "\n",
    "        # Update image with corrected state\n",
    "        image[i, 0] = corrected_state[0, 0]\n",
    "        image[i, 1] = corrected_state[1, 0]\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_roi(image):\n",
    "    # Manually define the Region of Interest (ROI)\n",
    "    x, y, w, h = 100, 50, 200, 150  # Example coordinates (adjust as needed)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "\n",
    "    # Convert the ROI to grayscale\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_roi = laplacian(gray_roi)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_roi1 = highPassFiltering(transformed_roi)\n",
    "\n",
    "    # Kalman Filtering\n",
    "    transformed_roi2 = kalman_filter(transformed_roi1)\n",
    "\n",
    "    # Apply Otsu's thresholding\n",
    "    _, thresholded_roi = cv2.threshold(transformed_roi2, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    return thresholded_roi\n",
    "\n",
    "# Loop over your dataset\n",
    "for segments in traintest_folder:\n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path, segments)\n",
    "\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "\n",
    "    # Individual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "\n",
    "        for i in images:\n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Preprocess the image within the ROI\n",
    "            preprocessed_roi = preprocess_roi(image)\n",
    "\n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), preprocessed_roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266933d4-6664-4cb4-a6a7-f5500aa3b1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f04af4-d667-4de9-8a89-36dbbf98192b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bdc544e-aae0-4e8a-b7e6-28b16bbfd88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test ----------------------------------------------\n",
      "Working on 0 ------------------\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\clahe.cpp:353: error: (-215:Assertion failed) _src.type() == CV_8UC1 || _src.type() == CV_16UC1 in function '`anonymous-namespace'::CLAHE_Impl::apply'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 133\u001b[0m\n\u001b[0;32m    130\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(join(input_class_folder, i), cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Preprocess the image within the ROI\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m preprocessed_roi \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_roi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m filename \u001b[38;5;241m=\u001b[39m join(output_class_folder, i)\n\u001b[0;32m    136\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filename), preprocessed_roi)\n",
      "Cell \u001b[1;32mIn[25], line 96\u001b[0m, in \u001b[0;36mpreprocess_roi\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     93\u001b[0m transformed_roi2 \u001b[38;5;241m=\u001b[39m kalman_filter(transformed_roi1)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Additional Preprocessing\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m enhanced_roi \u001b[38;5;241m=\u001b[39m \u001b[43menhance_contrast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_roi2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m hsv_roi \u001b[38;5;241m=\u001b[39m convert_to_hsv(enhanced_roi)\n\u001b[0;32m     98\u001b[0m denoised_roi \u001b[38;5;241m=\u001b[39m denoise_image(hsv_roi)\n",
      "Cell \u001b[1;32mIn[25], line 55\u001b[0m, in \u001b[0;36menhance_contrast\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menhance_contrast\u001b[39m(image):\n\u001b[0;32m     54\u001b[0m     clahe \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcreateCLAHE(clipLimit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m, tileGridSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m---> 55\u001b[0m     enhanced_image \u001b[38;5;241m=\u001b[39m \u001b[43mclahe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enhanced_image\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\clahe.cpp:353: error: (-215:Assertion failed) _src.type() == CV_8UC1 || _src.type() == CV_16UC1 in function '`anonymous-namespace'::CLAHE_Impl::apply'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "def laplacian(image):\n",
    "    # Apply Laplacian sharpening\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharpened_image = np.uint8(np.clip(image - 0.5 * laplacian, 0, 255))\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    unsharp_mask = cv2.addWeighted(image, 2, blurred, -1, 0)\n",
    "    sharpened_image = np.uint8(np.clip(unsharp_mask, 0, 255))\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "def highPassFiltering(image):\n",
    "    # Apply high-pass filtering\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def kalman_filter(image):\n",
    "    # Apply Kalman Filter to smooth the image\n",
    "    kalman = cv2.KalmanFilter(4, 2)\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = 1e-5 * np.eye(4, dtype=np.float32)\n",
    "    kalman.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32)\n",
    "\n",
    "    # Convert image to float32 for Kalman Filter\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Initialize Kalman Filter state\n",
    "    state = np.array([[image[0, 0]], [image[0, 1]], [0], [0]], dtype=np.float32)\n",
    "\n",
    "    for i in range(1, image.shape[0]):\n",
    "        # Predict\n",
    "        predicted_state = kalman.predict()\n",
    "\n",
    "        # Correct using measurement\n",
    "        measurement = np.array([[image[i, 0]], [image[i, 1]]], dtype=np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "\n",
    "        # Update image with corrected state\n",
    "        image[i, 0] = corrected_state[0, 0]\n",
    "        image[i, 1] = corrected_state[1, 0]\n",
    "\n",
    "    return image\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(image)\n",
    "    return enhanced_image\n",
    "\n",
    "def convert_to_hsv(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    return hsv_image\n",
    "\n",
    "def denoise_image(image):\n",
    "    denoised_image = cv2.medianBlur(image, 5)\n",
    "    return denoised_image\n",
    "\n",
    "def detect_edges(image):\n",
    "    edges = cv2.Canny(image, 50, 150)\n",
    "    return edges\n",
    "\n",
    "def resize_image(image, target_size=(200, 200)):\n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    return resized_image\n",
    "\n",
    "def gamma_correction(image, gamma=1.5):\n",
    "    gamma_corrected = np.power(image / 255.0, gamma) * 255.0\n",
    "    return gamma_corrected.astype('uint8')\n",
    "\n",
    "def preprocess_roi(image):\n",
    "    # Manually define the Region of Interest (ROI)\n",
    "    x, y, w, h = 100, 50, 200, 150  # Example coordinates (adjust as needed)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "\n",
    "    # Convert the ROI to grayscale\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Laplacian Transformation\n",
    "    transformed_roi = laplacian(gray_roi)\n",
    "\n",
    "    # High Pass Filtering\n",
    "    transformed_roi1 = highPassFiltering(transformed_roi)\n",
    "\n",
    "    # Kalman Filtering\n",
    "    transformed_roi2 = kalman_filter(transformed_roi1)\n",
    "\n",
    "    # Additional Preprocessing\n",
    "    enhanced_roi = enhance_contrast(transformed_roi2)\n",
    "    hsv_roi = convert_to_hsv(enhanced_roi)\n",
    "    denoised_roi = denoise_image(hsv_roi)\n",
    "    edges_roi = detect_edges(denoised_roi)\n",
    "    resized_roi = resize_image(edges_roi)\n",
    "\n",
    "    return resized_roi\n",
    "\n",
    "# Loop over your dataset\n",
    "for segments in traintest_folder:\n",
    "    print(\"Working on {} ----------------------------------------------\".format(segments))\n",
    "    # Train Test Val Folders\n",
    "    segment_path = join(input_path, segments)\n",
    "    output_segment_path = join(output_path, segments)\n",
    "\n",
    "    # Create Folder\n",
    "    if not os.path.exists(output_segment_path):\n",
    "        os.mkdir(output_segment_path)\n",
    "\n",
    "    # Individual Folders\n",
    "    classes = os.listdir(segment_path)\n",
    "    for class_folder in classes:\n",
    "        print(\"Working on {} ------------------\".format(class_folder))\n",
    "        input_class_folder = join(segment_path, class_folder)\n",
    "        output_class_folder = join(output_segment_path, class_folder)\n",
    "\n",
    "        # Create Folder\n",
    "        if not os.path.exists(output_class_folder):\n",
    "            os.mkdir(output_class_folder)\n",
    "\n",
    "        images = os.listdir(input_class_folder)\n",
    "\n",
    "        for i in images:\n",
    "            # Read Image\n",
    "            image = cv2.imread(join(input_class_folder, i), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Preprocess the image within the ROI\n",
    "            preprocessed_roi = preprocess_roi(image)\n",
    "\n",
    "            filename = join(output_class_folder, i)\n",
    "            cv2.imwrite(\"{}\".format(filename), preprocessed_roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066697e7-78b8-4774-b077-c32d614f4a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a79a0-705f-45ad-be72-aadd222eed09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a515034-6d70-4964-97ea-8d686a7138dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyWavelets\n",
      "  Downloading pywavelets-1.5.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "                                              0.0/4.3 MB ? eta -:--:--\n",
      "                                              0.0/4.3 MB ? eta -:--:--\n",
      "                                              0.0/4.3 MB ? eta -:--:--\n",
      "                                              0.0/4.3 MB 435.7 kB/s eta 0:00:10\n",
      "                                              0.1/4.3 MB 508.4 kB/s eta 0:00:09\n",
      "     -                                        0.1/4.3 MB 599.1 kB/s eta 0:00:07\n",
      "     -                                        0.2/4.3 MB 697.2 kB/s eta 0:00:06\n",
      "     --                                       0.2/4.3 MB 885.4 kB/s eta 0:00:05\n",
      "     ---                                      0.4/4.3 MB 1.2 MB/s eta 0:00:04\n",
      "     ----                                     0.5/4.3 MB 1.3 MB/s eta 0:00:03\n",
      "     -------                                  0.8/4.3 MB 1.8 MB/s eta 0:00:02\n",
      "     ---------                                1.0/4.3 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------                             1.4/4.3 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------                       1.9/4.3 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------                    2.3/4.3 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------              2.9/4.3 MB 4.4 MB/s eta 0:00:01\n",
      "     --------------------------------         3.4/4.3 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------        3.5/4.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------        3.5/4.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     3.9/4.3 MB 4.6 MB/s eta 0:00:01\n",
      "     --------------------------------------   4.1/4.3 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.2/4.3 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.3/4.3 MB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.0,>=1.22.4 in c:\\users\\fahim\\miniconda3\\lib\\site-packages (from PyWavelets) (1.26.2)\n",
      "Installing collected packages: PyWavelets\n",
      "Successfully installed PyWavelets-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyWavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "356d480e-f812-414a-9145-19dee366015f",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\median_blur.dispatch.cpp:283: error: (-215:Assertion failed) !_src0.empty() in function 'cv::medianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:/Desktop/test-image/median_bilateral_wavelet-based denoising/9585931R.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Apply Median Filtering\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m median_filtered_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedianBlur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Apply Bilateral Filtering\u001b[39;00m\n\u001b[0;32m     12\u001b[0m bilateral_filtered_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbilateralFilter(image, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m75\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\median_blur.dispatch.cpp:283: error: (-215:Assertion failed) !_src0.empty() in function 'cv::medianBlur'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "# Load the image from the dataset\n",
    "image = cv2.imread(\"E:/Desktop/test-image/median_bilateral_wavelet-based denoising/9585931R.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# Apply Median Filtering\n",
    "median_filtered_image = cv2.medianBlur(image, 5)\n",
    "\n",
    "# Apply Bilateral Filtering\n",
    "bilateral_filtered_image = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "\n",
    "# Apply Wavelet-based Denoising\n",
    "def wavelet_denoising(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform wavelet decomposition\n",
    "    coeffs = pywt.dwt2(gray, 'haar')\n",
    "    cA, (cH, cV, cD) = coeffs\n",
    "    \n",
    "    # Set a threshold value to denoise the coefficients\n",
    "    threshold = 20\n",
    "    \n",
    "    # Apply soft thresholding to the detail coefficients (cH, cV, cD)\n",
    "    denoised_coeffs = (cA, (pywt.threshold(cH, threshold), pywt.threshold(cV, threshold), pywt.threshold(cD, threshold)))\n",
    "    \n",
    "    # Perform inverse wavelet transform\n",
    "    denoised_gray = pywt.idwt2(denoised_coeffs, 'haar')\n",
    "    \n",
    "    # Convert the denoised grayscale image back to color\n",
    "    denoised_image = cv2.cvtColor(np.uint8(denoised_gray), cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    return denoised_image\n",
    "\n",
    "wavelet_denoised_image = wavelet_denoising(image)\n",
    "\n",
    "# Display the original and processed images\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Median Filtering\", median_filtered_image)\n",
    "cv2.imshow(\"Bilateral Filtering\", bilateral_filtered_image)\n",
    "cv2.imshow(\"Wavelet-based Denoising\", wavelet_denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff8a0c-7f74-47c4-a214-9f6969c2436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
